{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Natural Language Processing Lab\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we will further explore sklearn and NLTK's capabilities for processing text. We will use the 20 Newsgroup dataset, which is provided by sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    " \n",
    "plt.style.use('ggplot')\n",
    "sns.set(font_scale=1.5)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the Sklearn Dataset\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Use the `fetch_20newsgroups` function to download a training and testing set.\n",
    "\n",
    "Look up the [function documentation](http://scikit-learn.org/stable/datasets/twenty_newsgroups.html) for how to grab the data.\n",
    "\n",
    "You should pull these categories:\n",
    "- `alt.atheism`\n",
    "- `talk.religion.misc`\n",
    "- `comp.graphics`\n",
    "- `sci.space`\n",
    "\n",
    "Also remove the headers, footers, and quotes using the `remove` keyword argument of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Information from the Data's Dictionary format \n",
    "# Categories of emails we want\n",
    "categories = [\n",
    "    'alt.atheism',\n",
    "    'talk.religion.misc',\n",
    "    'comp.graphics',\n",
    "    'sci.space',\n",
    "]\n",
    "# Setting training data\n",
    "data_train = fetch_20newsgroups(subset='train', categories=categories,\n",
    "                                shuffle=True, random_state=42,\n",
    "                                remove=('headers', 'footers', 'quotes'))\n",
    "# Setting testing data\n",
    "data_test = fetch_20newsgroups(subset='test', categories=categories,\n",
    "                               shuffle=True, random_state=42,\n",
    "                               remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data inspection\n",
    "\n",
    "We have downloaded a few newsgroup categories and removed headers, footers and quotes.\n",
    "\n",
    "Because this is an sklearn dataset, it comes with pre-split train and test sets (note we were able to call 'train' and 'test' in subset).\n",
    "\n",
    "Let's inspect them.\n",
    "\n",
    "1. What data type is `data_train`?\n",
    "- What does `data_train` contain? \n",
    "- How many data points does `data_train` contain?\n",
    "- How many data points of each category does `data_train` contain?\n",
    "- Inspect the first data point, what does it look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A:\n",
    "#1.What data type is data_train?\n",
    "type(data_train)\n",
    "#Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR', 'description'])"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.What does data_train contain?\n",
    "data_train.keys()\n",
    "#['data', 'filenames', 'target_names', 'target', 'DESCR', 'description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2034\n",
      "2034\n"
     ]
    }
   ],
   "source": [
    "#3.How many data points does data_train contain?\n",
    "print(len(data_train.data))\n",
    "print(pd.DataFrame(data_train.data).shape[0])\n",
    "#2034 data points for data_train.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data 2034\n",
      "filenames 2034\n",
      "target_names 4\n",
      "target 2034\n",
      "DESCR 0\n",
      "description 33\n"
     ]
    }
   ],
   "source": [
    "#4.How many data points of each category does data_train contain?\n",
    "print('Data',len(data_train.data))\n",
    "print('filenames',len(data_train.filenames))\n",
    "print('target_names',len(data_train.target_names))\n",
    "print('target',len(data_train.target))\n",
    "print('DESCR',[0 if data_train.DESCR == None else len(data_train.DESCR)][0])\n",
    "print('description',len(data_train.description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi,\\n\\nI've noticed that if you only save a model (with all your mapping planes\\npositioned carefully) to a .3DS file that when you reload it after restarting\\n3DS, they are given a default position and orientation.  But if you save\\nto a .PRJ file their positions/orientation are preserved.  Does anyone\\nknow why this information is not stored in the .3DS file?  Nothing is\\nexplicitly said in the manual about saving texture rules in the .PRJ file. \\nI'd like to be able to read the texture rule information, does anyone have \\nthe format for the .PRJ file?\\n\\nIs the .CEL file format available from somewhere?\\n\\nRych\""
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5.Inspect the first data point, what does it look like?\n",
    "pd.DataFrame(data_train.data).iloc[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Bag of Words model\n",
    "\n",
    "Let's train a model using a simple count vectorizer.\n",
    "\n",
    "1. Initialize a standard CountVectorizer and fit the training data.\n",
    "- How big is the feature dictionary?\n",
    "- Repeat eliminating English stop words.\n",
    "- Is the dictionary smaller?\n",
    "- Transform the training data using the trained vectorizer.\n",
    "- What are the 20 words that are most common in the whole corpus?\n",
    "- What are the 20 most common words in each of the 4 classes?\n",
    "- Evaluate the performance of a Logistic Regression on the features extracted by the CountVectorizer.\n",
    "    - You will have to transform the test_set, too. Be careful to use the trained vectorizer, without re-fitting it.\n",
    "    - Create a confusion matrix.\n",
    "\n",
    "**BONUS:**\n",
    "- Try a couple of modifications:\n",
    "    - restrict max_features\n",
    "    - change max_df and min_df\n",
    "    - for each of the above print a confusion matrix and investigate what gets mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A:\n",
    "#1.Initialize a standard CountVectorizer and fit the training data.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer()\n",
    "cv.fit(data_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26879"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.How big is the feature dictionary?\n",
    "len(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26576"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3.Repeat eliminating English stop words.\n",
    "cv=CountVectorizer(stop_words='english')\n",
    "cv.fit(data_train.data)\n",
    "len(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.Is the dictionary smaller?\n",
    "#Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.Transform the training data using the trained vectorizer.\n",
    "data_mat=cv.transform(data_train.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>space</th>\n",
       "      <th>people</th>\n",
       "      <th>god</th>\n",
       "      <th>don</th>\n",
       "      <th>like</th>\n",
       "      <th>just</th>\n",
       "      <th>does</th>\n",
       "      <th>know</th>\n",
       "      <th>think</th>\n",
       "      <th>time</th>\n",
       "      <th>image</th>\n",
       "      <th>edu</th>\n",
       "      <th>use</th>\n",
       "      <th>good</th>\n",
       "      <th>data</th>\n",
       "      <th>nasa</th>\n",
       "      <th>graphics</th>\n",
       "      <th>jesus</th>\n",
       "      <th>say</th>\n",
       "      <th>way</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1061</td>\n",
       "      <td>793</td>\n",
       "      <td>745</td>\n",
       "      <td>730</td>\n",
       "      <td>682</td>\n",
       "      <td>675</td>\n",
       "      <td>600</td>\n",
       "      <td>592</td>\n",
       "      <td>584</td>\n",
       "      <td>546</td>\n",
       "      <td>534</td>\n",
       "      <td>501</td>\n",
       "      <td>468</td>\n",
       "      <td>449</td>\n",
       "      <td>444</td>\n",
       "      <td>419</td>\n",
       "      <td>414</td>\n",
       "      <td>411</td>\n",
       "      <td>409</td>\n",
       "      <td>387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   space  people  god  don  like  just  does  know  think  time  image  edu  \\\n",
       "0   1061     793  745  730   682   675   600   592    584   546    534  501   \n",
       "\n",
       "   use  good  data  nasa  graphics  jesus  say  way  \n",
       "0  468   449   444   419       414    411  409  387  "
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6.What are the 20 words that are most common in the whole corpus?\n",
    "pd.DataFrame(np.sum(data_mat.toarray(),axis=0),index=cv.get_feature_names()).sort_values(0,ascending=False).head(20).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7.What are the 20 most common words in each of the 4 classes?\n",
    "df2=pd.DataFrame(data_train.data)\n",
    "df2['target']=data_train.target\n",
    "\n",
    "all_classes=cv.fit_transform((str(df2[df2['target']==0][0]),str(df2[df2['target']==1][0]),\n",
    "                             str(df2[df2['target']==2][0]),str(df2[df2['target']==3][0])))\n",
    "\n",
    "df_4_classes=pd.DataFrame(all_classes.toarray(),columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ni</th>\n",
       "      <th>atheism</th>\n",
       "      <th>just</th>\n",
       "      <th>agree</th>\n",
       "      <th>read</th>\n",
       "      <th>state</th>\n",
       "      <th>nif</th>\n",
       "      <th>nit</th>\n",
       "      <th>nand</th>\n",
       "      <th>nmost</th>\n",
       "      <th>nno</th>\n",
       "      <th>post</th>\n",
       "      <th>does</th>\n",
       "      <th>nso</th>\n",
       "      <th>mean</th>\n",
       "      <th>point</th>\n",
       "      <th>nthis</th>\n",
       "      <th>think</th>\n",
       "      <th>deleted</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ni  atheism  just  agree  read  state  nif  nit  nand  nmost  nno  post  \\\n",
       "0   6        4     4      3     3      2    2    2     2      2    2     2   \n",
       "\n",
       "   does  nso  mean  point  nthis  think  deleted  object  \n",
       "0     2    2     2      2      2      2        2       2  "
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#class 0\n",
    "df_4_classes.T[[0]].sort_values(0,ascending=False).head(20).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ni</th>\n",
       "      <th>hi</th>\n",
       "      <th>looking</th>\n",
       "      <th>program</th>\n",
       "      <th>just</th>\n",
       "      <th>hello</th>\n",
       "      <th>interested</th>\n",
       "      <th>3d</th>\n",
       "      <th>68010</th>\n",
       "      <th>using</th>\n",
       "      <th>package</th>\n",
       "      <th>problem</th>\n",
       "      <th>ve</th>\n",
       "      <th>graphics</th>\n",
       "      <th>got</th>\n",
       "      <th>format</th>\n",
       "      <th>68070</th>\n",
       "      <th>file</th>\n",
       "      <th>files</th>\n",
       "      <th>trying</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ni  hi  looking  program  just  hello  interested  3d  68010  using  \\\n",
       "1   8   7        6        4     3      3           3   3      2      2   \n",
       "\n",
       "   package  problem  ve  graphics  got  format  68070  file  files  trying  \n",
       "1        2        2   2         2    2       2      2     2      2       2  "
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#class 1\n",
    "df_4_classes.T[[1]].sort_values(1,ascending=False).head(20).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ni</th>\n",
       "      <th>worse</th>\n",
       "      <th>article</th>\n",
       "      <th>did</th>\n",
       "      <th>just</th>\n",
       "      <th>spent</th>\n",
       "      <th>assuming</th>\n",
       "      <th>fuel</th>\n",
       "      <th>space</th>\n",
       "      <th>nhow</th>\n",
       "      <th>nit</th>\n",
       "      <th>test</th>\n",
       "      <th>remember</th>\n",
       "      <th>sq</th>\n",
       "      <th>early</th>\n",
       "      <th>performance</th>\n",
       "      <th>sure</th>\n",
       "      <th>nyou</th>\n",
       "      <th>dc</th>\n",
       "      <th>talk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ni  worse  article  did  just  spent  assuming  fuel  space  nhow  nit  \\\n",
       "2   4      3        3    3     3      2         2     2      2     2    2   \n",
       "\n",
       "   test  remember  sq  early  performance  sure  nyou  dc  talk  \n",
       "2     2         2   2      2            2     2     2   2     2  "
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#class 2\n",
    "df_4_classes.T[[2]].sort_values(2,ascending=False).head(20).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ni</th>\n",
       "      <th>don</th>\n",
       "      <th>nyou</th>\n",
       "      <th>point</th>\n",
       "      <th>want</th>\n",
       "      <th>replied</th>\n",
       "      <th>generally</th>\n",
       "      <th>jose</th>\n",
       "      <th>tell</th>\n",
       "      <th>deleted</th>\n",
       "      <th>said</th>\n",
       "      <th>mormons</th>\n",
       "      <th>think</th>\n",
       "      <th>god</th>\n",
       "      <th>letter</th>\n",
       "      <th>th</th>\n",
       "      <th>good</th>\n",
       "      <th>rick</th>\n",
       "      <th>nthe</th>\n",
       "      <th>quote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ni  don  nyou  point  want  replied  generally  jose  tell  deleted  said  \\\n",
       "3   5    3     3      3     2        2          2     2     2        2     2   \n",
       "\n",
       "   mormons  think  god  letter  th  good  rick  nthe  quote  \n",
       "3        2      2    2       2   2     2     2     2      2  "
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#class 3\n",
    "df_4_classes.T[[3]].sort_values(3,ascending=False).head(20).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7450110864745011 \n",
      "\n",
      "[[187  16  46  70]\n",
      " [ 13 345  28   3]\n",
      " [ 22  23 333  16]\n",
      " [ 67  14  27 143]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26576"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8.Evaluate the performance of a Logistic Regression on the features extracted by the CountVectorizer.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "lm=LogisticRegression()\n",
    "X_train=cv.fit_transform(data_train.data)\n",
    "y_train=data_train.target\n",
    "X_test=cv.transform(data_test.data)\n",
    "y_test=data_test.target\n",
    "lm.fit(X_train,y_train)\n",
    "print('accuracy:',lm.score(X_test,y_test),'\\n')\n",
    "print(confusion_matrix(y_test,lm.predict(X_test)))\n",
    "len(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Hashing and TF-IDF\n",
    "\n",
    "Let's see if Hashing or TF-IDF improves the accuracy.\n",
    "\n",
    "1. Initialize a HashingVectorizer and repeat the test with no restriction on the number of features.\n",
    "- Does the score improve with respect to the count vectorizer? \n",
    "- Print out the number of features for this model.\n",
    "- Initialize a TF-IDF Vectorizer and repeat the analysis above.\n",
    "\n",
    "**BONUS:**\n",
    "- Change the parameters of either (or both!) models to improve your score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6740576496674058 \n",
      "\n",
      "[[180  41  54  44]\n",
      " [ 15 337  34   3]\n",
      " [ 29  47 315   3]\n",
      " [100  29  42  80]]\n"
     ]
    }
   ],
   "source": [
    "# A:\n",
    "#1.Initialize a HashingVectorizer and repeat the test with no restriction on the number of features.\n",
    "from sklearn.feature_extraction.text import HashingVectorizer,TfidfVectorizer\n",
    "hash=HashingVectorizer()\n",
    "X_train=hash.fit_transform(data_train.data)\n",
    "X_test=hash.transform(data_test.data)\n",
    "lm.fit(X_train,y_train)\n",
    "print('accuracy:',lm.score(X_test,y_test),'\\n')\n",
    "print(confusion_matrix(y_test,lm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.Does the score improve with respect to the count vectorizer?\n",
    "#Nope it's worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1048576"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3.Print out the number of features for this model.\n",
    "hash.n_features\n",
    "#wow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7331855136733185 \n",
      "\n",
      "[[199  26  55  39]\n",
      " [ 11 349  27   2]\n",
      " [ 17  39 338   0]\n",
      " [ 86  25  34 106]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26879"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4.Initialize a TF-IDF Vectorizer and repeat the analysis above.\n",
    "tfidf=TfidfVectorizer()\n",
    "X_train=tfidf.fit_transform(data_train.data)\n",
    "X_test=tfidf.transform(data_test.data)\n",
    "lm.fit(X_train,y_train)\n",
    "print('accuracy:',lm.score(X_test,y_test),'\\n')\n",
    "print(confusion_matrix(y_test,lm.predict(X_test)))\n",
    "len(tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Classifier comparison\n",
    "\n",
    "Of all the vectorizers tested above, choose one that has a reasonable performance with a manageable number of features and compare the performance of these models:\n",
    "\n",
    "- KNN\n",
    "- Logistic Regression\n",
    "- Decision Trees\n",
    "- Support Vector Machine\n",
    "- Random Forest\n",
    "- Extra Trees\n",
    "\n",
    "In order to speed up the calculation it's better to vectorize the data only once and then compare the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cv=CountVectorizer(stop_words='english')\n",
    "X_train=cv.fit_transform(data_train.data)\n",
    "X_test=cv.transform(data_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=KNeighborsClassifier()\n",
    "knn.fit(X_train,y_train)\n",
    "knn_accuracy=accuracy_score(y_test,knn.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm=LogisticRegression()\n",
    "lm.fit(X_train,y_train)\n",
    "lm_accuracy=accuracy_score(y_test,lm.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree=DecisionTreeClassifier()\n",
    "dtree.fit(X_train,y_train)\n",
    "dtree_accuracy=accuracy_score(y_test,dtree.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm=SVC()\n",
    "svm.fit(X_train,y_train)\n",
    "svm_accuracy=accuracy_score(y_test,svm.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "rftree=RandomForestClassifier()\n",
    "rftree.fit(X_train,y_train)\n",
    "rftree_accuracy=accuracy_score(y_test,rftree.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "extree=ExtraTreesClassifier()\n",
    "extree.fit(X_train,y_train)\n",
    "extree_accuracy=accuracy_score(y_test,extree.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN                    accuracy: 0.3392461197339246\n",
      "Logistic Regression    accuracy: 0.7450110864745011\n",
      "Decision Tree          accuracy: 0.6134515890613451\n",
      "Support Vector Machine accuracy: 0.30524759793052475\n",
      "Random Forest          accuracy: 0.6289726533628973\n",
      "Extra Trees            accuracy: 0.647450110864745\n"
     ]
    }
   ],
   "source": [
    "print('KNN                    accuracy:',knn_accuracy)\n",
    "print('Logistic Regression    accuracy:',lm_accuracy)\n",
    "print('Decision Tree          accuracy:',dtree_accuracy)\n",
    "print('Support Vector Machine accuracy:',svm_accuracy)\n",
    "print('Random Forest          accuracy:',rftree_accuracy)\n",
    "print('Extra Trees            accuracy:',extree_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: Other classifiers\n",
    "\n",
    "Adapt the code from [this example](http://scikit-learn.org/stable/auto_examples/text/document_classification_20newsgroups.html#example-text-document-classification-20newsgroups-py) to compare across all the classifiers suggested and to display the final plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: \n",
    "\n",
    "- #### Fit a model to the 20newsgroups dataset with all classes\n",
    "\n",
    "- #### Choose texts, for example from newspaper articles, and check what is the class label predicted for them. Does the predicted label meet your expectations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
