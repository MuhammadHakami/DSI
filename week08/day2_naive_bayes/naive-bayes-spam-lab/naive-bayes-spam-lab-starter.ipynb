{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png\" style=\"float: left; margin: 15px;\">\n",
    "\n",
    "## Naive Bayes Spam Filter Using SpamAssassin Data\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "In this lab, we will write our own spam filter -- one of the many practical uses of Naive Bayes. We will additionally explore methods for visualizing text features in an effort to gain insight and improve our models.\n",
    "\n",
    "### Background\n",
    "\n",
    "The statistical approach for classifying spam was championed by Paul Graham, founder of Y Combinator. We highly recommend you read his classic (and very readable!) essay [A Plan for Spam](http://www.paulgraham.com/spam.html) to gain insight into why Naive Bayes works so well with spam.\n",
    "\n",
    "The reason why Naive Bayes works incredibly well to classify spam is because spam aligns with the independence assumption. Certain keywords in emails -- taken by themselves (e.g. Nigeria / prince) -- typically indicate a spam message.\n",
    "\n",
    "In this lab, the word **ham** indicates an email message that was authorized by the user. Sometimes we receive advertising emails that look like spam, yet we agreed to receive them. This fact can make spam detection more difficult. For a challenge, try classifying the `hard_ham` dataset below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Download the data\n",
    "\n",
    "We are using the data files from the SpamAssassin dataset:\n",
    "\n",
    "+ https://spamassassin.apache.org/old/publiccorpus/20021010_easy_ham.tar.bz2\n",
    "+ https://spamassassin.apache.org/old/publiccorpus/20021010_hard_ham.tar.bz2\n",
    "+ https://spamassassin.apache.org/old/publiccorpus/20021010_spam.tar.bz2\n",
    "\n",
    "From the command line, you can either use ```curl``` to download into the current directory. For an example of each:\n",
    "\n",
    "    curl http://spamassassin.apache.org/old/publiccorpus/20021010_easy_ham.tar.bz2 > 20021010_easy_ham.tar.bz2\n",
    "\n",
    "You can use ```tar xvf <file>``` to extract into the current directory (x - extract, v - verbose, f - read from file). For example:\n",
    "\n",
    "    tar xvf 20021010_easy_ham.tar.bz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get directory contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./datasets/spam/0355.94ebf637e4bd3db8a81c8ce68ecf681d',\n",
       " './datasets/spam/0395.bb934e8b4c39d5eab38f828a26f760b4',\n",
       " './datasets/spam/0485.9021367278833179285091e5201f5854',\n",
       " './datasets/spam/0343.0630afbe4ee1ffd0db0ffb81c6de98de',\n",
       " './datasets/spam/0125.44381546181fc6c5d7ea59e917f232c5',\n",
       " './datasets/spam/0108.4506c2ef846b80b9a7beb90315b22701',\n",
       " './datasets/spam/0112.ec411d26d1f4decc16af7ef73e69a227',\n",
       " './datasets/spam/0060.140f80780520fa19b360ddcb05838a67',\n",
       " './datasets/spam/0392.9e194dfff92f7d9957171b04a8d4b957',\n",
       " './datasets/spam/0441.b820c1999715c2e5ded6418d2b17723c']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: Ensure base_dir points to the base directory where you extracted your data files!\n",
    "#   Inside this directory should be three folders -- easy_ham, hard_ham, and spam.\n",
    "\n",
    "base_dir = './datasets'\n",
    "easy_ham_files = glob.glob(base_dir + \"/easy_ham/*\")\n",
    "hard_ham_files = glob.glob(base_dir + \"/hard_ham/*\")\n",
    "spam_files = glob.glob(base_dir + \"/spam/*\")\n",
    "spam_files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From rssfeeds@jmason.org  Mon Sep 30 13:43:46 2002\n",
      "Return-Path: <rssfeeds@example.com>\n",
      "Delivered-To: yyyy@localhost.example.com\n",
      "Received: from localhost (jalapeno [127.0.0.1])\n",
      "\tby jmason.org (Postfix) with ESMTP id AE79816F16\n",
      "\tfor <jm@localhost>; Mon, 30 Sep 2002 13:43:46 +0100 (IST)\n",
      "Received: from jalapeno [127.0.0.1]\n",
      "\tby localhost with IMAP (fetchmail-5.9.0)\n",
      "\tfor jm@localhost (single-drop); Mon, 30 Sep 2002 13:43:46 +0100 (IST)\n",
      "Received: from dogma.slashnull.org (localhost [127.0.0.1]) by\n",
      "    dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g8U81fg21359 for\n",
      "    <jm@jmason.org>; Mon, 30 Sep 2002 09:01:41 +0100\n",
      "Message-Id: <200209300801.g8U81fg21359@dogma.slashnull.org>\n",
      "To: yyyy@example.com\n",
      "From: gamasutra <rssfeeds@example.com>\n",
      "Subject: Priceless Rubens works stolen in raid on mansion\n",
      "Date: Mon, 30 Sep 2002 08:01:41 -0000\n",
      "Content-Type: text/plain; encoding=utf-8\n",
      "Lines: 6\n",
      "X-Spam-Status: No, hits=-527.4 required=5.0\n",
      "\ttests=AWL,DATE_IN_PAST_03_06,T_URI_COUNT_0_1\n",
      "\tversion=2.50-cvs\n",
      "X-Spam-Level: \n",
      "\n",
      "URL: http://www.newsisfree.com/click/-1,8381145,215/\n",
      "Date: 2002-09-30T03:04:58+01:00\n",
      "\n",
      "*Arts:* Fourth art raid on philanthropist's home once targeted by the IRA and \n",
      "Dublin gangster Martin Cahill.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use Python 3's open function, which supports the encoding parameter\n",
    "from io import open\n",
    "\n",
    "# Create list of full-text of all ham and spam emails\n",
    "\n",
    "# read the easy ham files into a list\n",
    "easy_ham_text = []\n",
    "for filename in easy_ham_files:\n",
    "    with open(filename, 'r', encoding='iso-8859-15') as f:\n",
    "        easy_ham_text.append(f.read())\n",
    "\n",
    "# read the easy ham files into a list\n",
    "hard_ham_text = []\n",
    "for filename in hard_ham_files:\n",
    "    with open(filename, 'r', encoding='iso-8859-15') as f:\n",
    "        hard_ham_text.append(f.read())\n",
    "        \n",
    "# read the spam files into a list\n",
    "spam_text = []\n",
    "for filename in spam_files:\n",
    "    with open(filename, 'r', encoding='iso-8859-15') as f:\n",
    "        spam_text.append(f.read())\n",
    "\n",
    "print(easy_ham_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's merge all of the emails into a single list of emails -- this is our data!\n",
    "ham_and_spam_text = easy_ham_text + spam_text    # extends the lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467\n",
      "2374\n",
      "2841\n"
     ]
    }
   ],
   "source": [
    "# How imbalanced is our dataset?\n",
    "\n",
    "print(len(spam_text))\n",
    "print(len(easy_ham_text))\n",
    "print(len(ham_and_spam_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Label the data\n",
    "\n",
    "We now have `ham_and_spam_text`, a single list containing our emails. However, now we need this data to be labeled with what we will predict. In this case, we will make a list of 0s and 1s indicating whether each of these emails is ham (0) or spam (1). Can you make this list, given how we combined the spam and ham into one list above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shadow/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "467"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(ham_and_spam_text)\n",
    "df['label']=0\n",
    "df['label'].iloc[2374:]=1\n",
    "df.label.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Transform the emails into features\n",
    " \n",
    "We will be using cross validation later to assess performance, so feel free to fit it on the entire dataset for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.A. Fit the model on your data using `CountVectorizer`\n",
    "\n",
    "Using `CountVectorizer` ONLY, transform each email into features. Consider now or later removing stopwords, trying different ngram sizes, making all words lowercase, and/or creating your own features (e.g. presence of an unsubscribe link!). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we are going to create a fct to stemmer the words in the email\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "# Return a callable that handles preprocessing and tokenization\n",
    "analyzer = CountVectorizer(stop_words='english').build_analyzer()\n",
    "\n",
    "def stemmed_words(doc):\n",
    "    return [stemmer.stem(w) for w in analyzer(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'rssfeeds', 'jmason', 'org', 'mon', 'sep', '30...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'fork', 'admin', 'xent', 'com', 'tue', 'sep', ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'exmh', 'users', 'admin', 'redhat', 'com', 'we...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'fork', 'admin', 'xent', 'com', 'mon', 'sep', ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'rssfeeds', 'jmason', 'org', 'fri', 'sep', '27...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  label\n",
       "0  'rssfeeds', 'jmason', 'org', 'mon', 'sep', '30...      0\n",
       "1  'fork', 'admin', 'xent', 'com', 'tue', 'sep', ...      0\n",
       "2  'exmh', 'users', 'admin', 'redhat', 'com', 'we...      0\n",
       "3  'fork', 'admin', 'xent', 'com', 'mon', 'sep', ...      0\n",
       "4  'rssfeeds', 'jmason', 'org', 'fri', 'sep', '27...      0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can now apply it using the countvectorizer from sklearn:\n",
    "df[0]=df[0].apply(lambda x: stemmer.stem(str(analyzer(x)))[1:-2])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.B. Transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer(stop_words='english')\n",
    "trans=cv.fit_transform(df[0].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.C. Create a sparse matrix for scikit-learn\n",
    "\n",
    "Create a dense 2-D ndarray `X` from the sparse matrix. Make a 1-D ndarray `y` (the list of labels you created earlier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2841, 77191), (2841,))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=trans.toarray()\n",
    "y=df.label\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Understand and visualize your features\n",
    "\n",
    "Sometimes you may find it difficult to visualize text data. This section provides some exercises that give you insight into how you may modify your text features for improved performance.\n",
    "\n",
    "#### 4.A. Understand sparse matrices and the transform\n",
    "\n",
    "**For email index 1, print(a list of words and counts, sorted by descending count.** Use only the `train_X` sparse matrix along with the `get_feature_names()` method of your vectorizer. The index of each column in `train_X` refers to a word. That word is given by the element at that same index in `get_feature_names()`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>com</th>\n",
       "      <th>fork</th>\n",
       "      <th>xent</th>\n",
       "      <th>wireless</th>\n",
       "      <th>mesh</th>\n",
       "      <th>2002</th>\n",
       "      <th>mobile</th>\n",
       "      <th>sep</th>\n",
       "      <th>networks</th>\n",
       "      <th>org</th>\n",
       "      <th>...</th>\n",
       "      <th>canadians</th>\n",
       "      <th>canada</th>\n",
       "      <th>campfire</th>\n",
       "      <th>camworld</th>\n",
       "      <th>camtel</th>\n",
       "      <th>cams</th>\n",
       "      <th>campus</th>\n",
       "      <th>camps</th>\n",
       "      <th>camping</th>\n",
       "      <th>žš</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 77191 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   com  fork  xent  wireless  mesh  2002  mobile  sep  networks  org ...  \\\n",
       "1   25    16    16        13    12    11      11   10         9    8 ...   \n",
       "\n",
       "   canadians  canada  campfire  camworld  camtel  cams  campus  camps  \\\n",
       "1          0       0         0         0       0     0       0      0   \n",
       "\n",
       "   camping  žš  \n",
       "1        0   0  \n",
       "\n",
       "[1 rows x 77191 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X,columns=cv.get_feature_names()).iloc[[1]].sort_values(1,axis=1,ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Notice that the most common words in the email are garbage words from the email header! \n",
    "- You can likely improve your model by filtering these in some way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.B. Using a histogram, visualize the number of emails each word is in.\n",
    "\n",
    "What distribution is it? From this histogram, will most words in your model be noise or signal? Seeing this histogram, what can you likely do to improve your model? (Hint: To quickly graph this, use `np.sum` on the dense matrix `X` of word counts!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "plt.hist(np.sum(X,axis=0),bins=20);\n",
    "# the distribution is rightly skewed. about all emails has atleast one unique work, which can be seen as noise.\n",
    "# maybe get ride of the words that occured at least once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.C. Using a histogram, visualize the number of words each email contains.\n",
    "\n",
    "What is the distribution? Are there any outlier emails? Can you find an explanation why there is there likely a spike in the histogram (e.g. are the emails in this dataset of a particular type?) \n",
    "\n",
    "- Plot the distribution of number of words for spam emails on top of the distribution for ham emails! Would this be a useful additional feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAESVJREFUeJzt3X+o3Xd9x/Hna4mt88dsatOSpWGJkokVtlpCrXSI05n+cFgFhZRhg+uIbC0oE0aqsDpF0DF1CK4aZ2YFbe38MYNmq1nsEAfW3NbYNsbYa83sNbGJVqub4Nb63h/nc+1penN/5ebek3yeDzh8v+d9Pt/v9/3NubmvnO+Pk1QVkqT+/MZSNyBJWhoGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTy5e6gemcc845tXbt2qVuQ5JOKXfdddePqmrlTONGOgDWrl3L2NjYUrchSaeUJP81m3EeApKkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE6N9J3AJ2rt1i8uyXYPvvuVS7JdSZoLPwFIUqcMAEnqlAEgSZ0yACSpUwaAJHVqxgBIsibJHUn2J9mX5E2t/vYkP0iytz2uHFrmhiTjSQ4kuWyofnmrjSfZenJ2SZI0G7O5DPRR4C1VdXeSZwJ3JdnVXnt/Vf3d8OAkFwCbgBcAvw38e5LfbS9/EHgFMAHsSbKjqr61EDsiSZqbGQOgqg4Dh9v8z5PsB1ZPs8hVwK1V9Uvge0nGgYvba+NV9QBAklvbWANAkpbAnM4BJFkLvBC4s5WuT3JPku1JVrTaauDBocUmWu14dUnSEph1ACR5BvAZ4M1V9TPgJuC5wIUMPiG8d3LoFIvXNPVjt7MlyViSsaNHj862PUnSHM0qAJI8hcEv/09U1WcBquqhqnqsqn4FfITHD/NMAGuGFj8fODRN/QmqaltVbaiqDStXzvif2kuS5mk2VwEF+Ciwv6reN1RfNTTsNcB9bX4HsCnJmUnWAeuBrwN7gPVJ1iU5g8GJ4h0LsxuSpLmazVVAlwKvB+5NsrfV3gpcneRCBodxDgJvBKiqfUluY3By91Hguqp6DCDJ9cDtwDJge1XtW8B9kSTNwWyuAvoqUx+/3znNMu8C3jVFfed0y0mSFo93AktSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROzRgASdYkuSPJ/iT7kryp1c9OsivJ/W26otWT5ANJxpPck+SioXVtbuPvT7L55O2WJGkms/kE8Cjwlqp6PnAJcF2SC4CtwO6qWg/sbs8BrgDWt8cW4CYYBAZwI/Ai4GLgxsnQkCQtvhkDoKoOV9Xdbf7nwH5gNXAVcHMbdjPw6jZ/FfDxGvgacFaSVcBlwK6qeriqfgLsAi5f0L2RJM3anM4BJFkLvBC4Ezivqg7DICSAc9uw1cCDQ4tNtNrx6pKkJTDrAEjyDOAzwJur6mfTDZ2iVtPUj93OliRjScaOHj062/YkSXM0qwBI8hQGv/w/UVWfbeWH2qEd2vRIq08Aa4YWPx84NE39CapqW1VtqKoNK1eunMu+SJLmYDZXAQX4KLC/qt439NIOYPJKns3A54fq17SrgS4BHmmHiG4HNiZZ0U7+bmw1SdISWD6LMZcCrwfuTbK31d4KvBu4Lcm1wPeB17XXdgJXAuPAL4A3AFTVw0neCexp495RVQ8vyF5IkuZsxgCoqq8y9fF7gJdPMb6A646zru3A9rk0KEk6ObwTWJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkTs0YAEm2JzmS5L6h2tuT/CDJ3va4cui1G5KMJzmQ5LKh+uWtNp5k68LviiRpLmbzCeBjwOVT1N9fVRe2x06AJBcAm4AXtGX+IcmyJMuADwJXABcAV7exkqQlsnymAVX1lSRrZ7m+q4Bbq+qXwPeSjAMXt9fGq+oBgCS3trHfmnPHkqQFcSLnAK5Pck87RLSi1VYDDw6NmWi149UlSUtkvgFwE/Bc4ELgMPDeVs8UY2ua+pMk2ZJkLMnY0aNH59meJGkm8wqAqnqoqh6rql8BH+HxwzwTwJqhoecDh6apT7XubVW1oao2rFy5cj7tSZJmYV4BkGTV0NPXAJNXCO0ANiU5M8k6YD3wdWAPsD7JuiRnMDhRvGP+bUuSTtSMJ4GT3AK8FDgnyQRwI/DSJBcyOIxzEHgjQFXtS3Ibg5O7jwLXVdVjbT3XA7cDy4DtVbVvwfdGkjRrs7kK6Oopyh+dZvy7gHdNUd8J7JxTd5Kkk8Y7gSWpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnZgyAJNuTHEly31Dt7CS7ktzfpitaPUk+kGQ8yT1JLhpaZnMbf3+SzSdndyRJszWbTwAfAy4/prYV2F1V64Hd7TnAFcD69tgC3ASDwABuBF4EXAzcOBkakqSlMWMAVNVXgIePKV8F3NzmbwZePVT/eA18DTgrySrgMmBXVT1cVT8BdvHkUJEkLaL5ngM4r6oOA7Tpua2+GnhwaNxEqx2vLklaIgt9EjhT1Gqa+pNXkGxJMpZk7OjRowvanCTpcfMNgIfaoR3a9EirTwBrhsadDxyapv4kVbWtqjZU1YaVK1fOsz1J0kzmGwA7gMkreTYDnx+qX9OuBroEeKQdIrod2JhkRTv5u7HVJElLZPlMA5LcArwUOCfJBIOred4N3JbkWuD7wOva8J3AlcA48AvgDQBV9XCSdwJ72rh3VNWxJ5YlSYtoxgCoqquP89LLpxhbwHXHWc92YPucupMknTTeCSxJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqdOKACSHExyb5K9ScZa7ewku5Lc36YrWj1JPpBkPMk9SS5aiB2QJM3PQnwC+MOqurCqNrTnW4HdVbUe2N2eA1wBrG+PLcBNC7BtSdI8nYxDQFcBN7f5m4FXD9U/XgNfA85KsuokbF+SNAsnGgAFfCnJXUm2tNp5VXUYoE3PbfXVwINDy0602hMk2ZJkLMnY0aNHT7A9SdLxLD/B5S+tqkNJzgV2Jfn2NGMzRa2eVKjaBmwD2LBhw5NelyQtjBP6BFBVh9r0CPA54GLgoclDO216pA2fANYMLX4+cOhEti9Jmr95B0CSpyd55uQ8sBG4D9gBbG7DNgOfb/M7gGva1UCXAI9MHiqSJC2+EzkEdB7wuSST6/lkVf1bkj3AbUmuBb4PvK6N3wlcCYwDvwDecALbliSdoHkHQFU9APz+FPUfAy+fol7AdfPdniRpYXknsCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnli91A6ejtVu/uGTbPvjuVy7ZtiWdWvwEIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASerUogdAksuTHEgynmTrYm9fkjSwqHcCJ1kGfBB4BTAB7Emyo6q+tZh9nM6W6i5k70CWTj2L/QngYmC8qh6oqv8FbgWuWuQeJEks/ncBrQYeHHo+AbxokXvQSbCU33+0VPzUo1PdYgdApqjVEwYkW4At7el/Jzkwx22cA/xoHr0ttlOhT3ucRt4z66H+OS6cU6HPUejxd2YzaLEDYAJYM/T8fODQ8ICq2gZsm+8GkoxV1Yb5Lr9YToU+7XFh2OPCORX6PBV6nLTY5wD2AOuTrEtyBrAJ2LHIPUiSWORPAFX1aJLrgduBZcD2qtq3mD1IkgYW/T+EqaqdwM6TuIl5Hz5aZKdCn/a4MOxx4ZwKfZ4KPQKQqpp5lCTptONXQUhSp06rAFjKr5lIsj3JkST3DdXOTrIryf1tuqLVk+QDrc97klw0tMzmNv7+JJsXuMc1Se5Isj/JviRvGrU+kzw1ydeTfLP1+Detvi7JnW17n2oXEZDkzPZ8vL2+dmhdN7T6gSSXLVSPQ+tfluQbSb4wwj0eTHJvkr1JxlptZN7vtu6zknw6ybfbz+aLR6nHJM9rf36Tj58lefMo9ThvVXVaPBicVP4u8BzgDOCbwAWLuP2XABcB9w3V/hbY2ua3Au9p81cC/8rgvohLgDtb/WzggTZd0eZXLGCPq4CL2vwzge8AF4xSn21bz2jzTwHubNu+DdjU6h8C/rzN/wXwoTa/CfhUm7+g/QycCaxrPxvLFvg9/0vgk8AX2vNR7PEgcM4xtZF5v9v6bwb+rM2fAZw1aj0O9boM+CGD6+xHssc57c9SbnyB35gXA7cPPb8BuGGRe1jLEwPgALCqza8CDrT5DwNXHzsOuBr48FD9CeNOQr+fZ/C9TCPZJ/A04G4Gd4v/CFh+7HvN4IqyF7f55W1cjn3/h8ctUG/nA7uBlwFfaNscqR7bOg/y5AAYmfcb+C3ge7TzkaPY4zF9bQT+c5R7nMvjdDoENNXXTKxeol4mnVdVhwHa9NxWP16vi7YP7TDECxn8C3uk+myHVvYCR4BdDP5l/NOqenSK7f26l/b6I8CzT3aPwN8DfwX8qj1/9gj2CIM77b+U5K4M7rKH0Xq/nwMcBf6pHU77xyRPH7Eeh20Cbmnzo9rjrJ1OATDj10yMkOP1uij7kOQZwGeAN1fVz6Ybepx+TmqfVfVYVV3I4F/ZFwPPn2Z7i95jkj8GjlTVXcPlaba3lO/3pVV1EXAFcF2Sl0wzdin6XM7g0OlNVfVC4H8YHE45niX7s2zndF4F/PNMQ4/Ty8j9jjqdAmDGr5lYAg8lWQXQpkda/Xi9nvR9SPIUBr/8P1FVnx3VPgGq6qfAfzA4jnpWksn7Voa39+te2uvPAh4+yT1eCrwqyUEG32j7MgafCEapRwCq6lCbHgE+xyBQR+n9ngAmqurO9vzTDAJhlHqcdAVwd1U91J6PYo9zcjoFwCh+zcQOYPJM/2YGx9wn69e0qwUuAR5pHyFvBzYmWdGuKNjYagsiSYCPAvur6n2j2GeSlUnOavO/CfwRsB+4A3jtcXqc7P21wJdrcIB1B7CpXYGzDlgPfH0heqyqG6rq/Kpay+Dn7MtV9Sej1CNAkqcneebkPIP36T5G6P2uqh8CDyZ5Xiu9HPjWKPU45GoeP/wz2cuo9Tg3S3kCYqEfDM6+f4fBMeO3LfK2bwEOA//HIOmvZXCcdzdwf5ue3caGwX+M813gXmDD0Hr+FBhvjzcscI9/wOAj5z3A3va4cpT6BH4P+Ebr8T7gr1v9OQx+OY4z+Ah+Zqs/tT0fb68/Z2hdb2u9HwCuOEnv+0t5/Cqgkeqx9fPN9tg3+XdilN7vtu4LgbH2nv8LgytkRq3HpwE/Bp41VBupHufz8E5gSerU6XQISJI0BwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmd+n86pWMXpI/vNgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.sum(X,axis=1));\n",
    "# the distribution is rightly skewed due to most emails having low number of words. we can see that however there are some emails with very high number of words(outliers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1af0d0f748>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['length']=df[0].map(len)\n",
    "plt.hist(np.sum(X[:2374,:],axis=1),label='ham')\n",
    "plt.hist(np.sum(X[2374:,:],axis=1),label='spam')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Estimate generalization accuracy\n",
    "\n",
    "Use `cross_val_score` with the models `BernoulliNB` and `MultinomialNB` to assess how well these models classify emails. Can you guess why one may perform better than the other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9032089746555645"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(BernoulliNB(),X,y,cv=3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9767679835383527"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(MultinomialNB(),X,y,cv=3).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Confusion matrix and Classification report\n",
    "\n",
    "Recall that to make a confusion matrix, we will need a specific split. So, use `test_train_split`, manually fit the model using the best performer, then find the confusion matrix and classificaation report (in the `metrics` package). Is your model worse at Type I or Type II errors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=11037,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.91      0.95       528\n",
      "          1       0.43      0.90      0.58        41\n",
      "\n",
      "avg / total       0.95      0.91      0.92       569\n",
      "\n",
      "BernoulliNB: \n",
      " [[478  50]\n",
      " [  4  37]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "bernb=BernoulliNB()\n",
    "mulnb=MultinomialNB()\n",
    "bernb.fit(X_train,y_train)\n",
    "mulnb.fit(X_train,y_train)\n",
    "\n",
    "print('BernoulliNB:','\\n',classification_report(bernb.predict(X_test),y_test))\n",
    "print('BernoulliNB:','\\n',confusion_matrix(bernb.predict(X_test),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99       490\n",
      "          1       0.91      1.00      0.95        79\n",
      "\n",
      "avg / total       0.99      0.99      0.99       569\n",
      "\n",
      "MultinomialNB: \n",
      " [[482   8]\n",
      " [  0  79]]\n"
     ]
    }
   ],
   "source": [
    "print('MultinomialNB:','\\n',classification_report(mulnb.predict(X_test),y_test))\n",
    "print('MultinomialNB:','\\n',confusion_matrix(mulnb.predict(X_test),y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model on the hard_ham\n",
    "\n",
    "Does it perform as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3203463203463204"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_hard_ham=cv.transform(hard_ham_text)\n",
    "hard_ham_predictions=mulnb.predict(transformed_hard_ham.toarray())\n",
    "1-hard_ham_predictions.mean()\n",
    "# awful perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 74,   0],\n",
       "       [157,   0]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(hard_ham_predictions,np.zeros_like(hard_ham_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Improve your model by looking at mispredictions\n",
    "\n",
    "print(the most common words in your false positives of the hard hams versus the spams. (Perhaps write a function of step 4A. Consider using a `collections.Counter` to combine the counts!) Does comparing the most frequent words in the hard ham to those in the spam give you some ideas for how to distinguish between them? What extra features might you add to your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>td</th>\n",
       "      <td>21059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>com</th>\n",
       "      <td>19756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http</th>\n",
       "      <td>17756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>width</th>\n",
       "      <td>16541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3d</th>\n",
       "      <td>13517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>font</th>\n",
       "      <td>11981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr</th>\n",
       "      <td>10553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>www</th>\n",
       "      <td>9927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>br</th>\n",
       "      <td>9394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>height</th>\n",
       "      <td>9328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>src</th>\n",
       "      <td>8971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img</th>\n",
       "      <td>8872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gif</th>\n",
       "      <td>8799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>href</th>\n",
       "      <td>7547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09</th>\n",
       "      <td>6886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>border</th>\n",
       "      <td>6860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnet</th>\n",
       "      <td>5968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>table</th>\n",
       "      <td>5877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size</th>\n",
       "      <td>5409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bgcolor</th>\n",
       "      <td>5252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "td       21059\n",
       "com      19756\n",
       "http     17756\n",
       "width    16541\n",
       "3d       13517\n",
       "font     11981\n",
       "tr       10553\n",
       "www       9927\n",
       "br        9394\n",
       "height    9328\n",
       "src       8971\n",
       "img       8872\n",
       "gif       8799\n",
       "href      7547\n",
       "09        6886\n",
       "border    6860\n",
       "cnet      5968\n",
       "table     5877\n",
       "size      5409\n",
       "bgcolor   5252"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_ham_df=pd.DataFrame(transformed_hard_ham.toarray(),columns=cv.get_feature_names())\n",
    "hard_ham_df['predicted_label']=hard_ham_predictions\n",
    "labeled_1=hard_ham_df[hard_ham_df['predicted_label']==1].sum(axis=0).sort_values(ascending=False)\n",
    "labeled_1=labeled_1[~(labeled_1==0)]\n",
    "pd.DataFrame(labeled_1).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extensions\n",
    "\n",
    "- Can you improve the score on the hard ham?\n",
    "- Try to improve your model by changing or tweaking the model type. (e.g. LogisticRegression/RandomForests) Why do bigrams result in a lower accuracy? (Because nearly all of them are single-email, so they actually add MORE noise!)\n",
    "- Remove features from your model, e.g. junk words.\n",
    "- Add additional features to your model. Can you specifically come up with ideas that might detect spam vs. ham? For example, does an email have an unsubscribe link?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
