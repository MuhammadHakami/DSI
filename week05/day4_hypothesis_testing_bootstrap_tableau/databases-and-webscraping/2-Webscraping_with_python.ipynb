{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping from a Web Page with Python\n",
    "\n",
    "Scraping a web site basically comes down to making a request from Python and parsing through the HTML that is returned from each page. For each of these tasks we have a Python library, `requests` and `bs4`, respectively.\n",
    "\n",
    "### Requests Library\n",
    "\n",
    "The [requests](http://docs.python-requests.org/en/latest/index.html) library is designed to simplify the process of making http requests within Python. The interface is mind-bogglingly simple. Instantiate a requests object to the request, this will mostly be a `get`, with the URL and optional parameters you'd like passed through the request. That instance make the results of the request available via attributes/methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "fun_cheap = 'http://sf.funcheap.com'\n",
    "r = requests.get('http://sf.funcheap.com/2018/03/25/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\\n<html xmlns=\"https://www.w3.org/1999/xhtml\" lang=\"en-US\" xmlns:fb=\"http://www.facebook.com/2008/fbml\" xmlns:og=\"http://opengraphprotocol.org/schema/\" prefix=\"og: http://ogp.me/ns#\">\\n\\n<head profile=\"https://gmpg.org/xfn/11\">\\n<script src=\"//cdn.optimizely.com/js/195632799.js\"></script>\\n\\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" />\\n\\n\\n<title>Events for March 25, 2018 Archives - Funcheap</title>\\n\\n<meta name=\"generator\" content=\"WordPress\" /> <!-- leave this for stats -->\\n\\n<link rel=\"stylesheet\" href=\"https://cdn.funcheap.com/wp-content/themes/arthemia-premium/style.css?v=1.8.14\" type=\"text/css\" media=\"screen\" />\\n<link rel=\"stylesheet\" href=\"https://cdn.funcheap.com/wp-content/themes/arthemia-premium/madmenu.css?v=1.1\" type=\"text/css\" media=\"screen\" />\\n<!--[if IE 6]>\\n    <style type=\"text/css\">\\n    body {\\n        behavior:url(\"https://cdn.funchea'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.text[:1000] # First 1000 characters of the HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Info from a Web Page\n",
    "\n",
    "Now that we can gain easy access to the HMTL for a web page, we need some way to pull the desired content from it. Luckily there is already a system in place to do this. With a combination of HMTL and CSS selectors we can identify the information on a HMTL page that we wish to retrieve and grab it with [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#searching-the-tree)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Element Parent / Child Relationships\n",
    "\n",
    "<img src=\"http://www.htmlgoodies.com/img/2007/06/flowChart2.gif\" width=\"250\">\n",
    "\n",
    "**Elements begin and end in the same namespace like so:**  `<p></p>`\n",
    "\n",
    "**Elements can have parents and children:**\n",
    "\n",
    "```html\n",
    "<body>\n",
    "    <div>I am inside the parent element\n",
    "        <div>I am inside a child element</div>\n",
    "        <div>I am inside another child element</div>\n",
    "        <div>I am inside yet another child element</div>\n",
    "    </div>\n",
    "</body>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='attributes'></a>\n",
    "\n",
    "## Element Attributes\n",
    "\n",
    "Elements can also have attributes!  Attributes are defined inside **element tags** and can contain data that may be useful to scrape.\n",
    "\n",
    "```html\n",
    "<a href=\"http://lmgtfy.com/?q=html+element+attributes\" title=\"A title\" id=\"web-link\" name=\"hal\">A Simple Link</a>\n",
    "```\n",
    "\n",
    "The **element attributes** of this `<a>` tag element are:\n",
    "- id\n",
    "- href\n",
    "- title\n",
    "- name\n",
    "\n",
    "This `<a>` tag example will render in your browser like this:\n",
    "> <a href=\"https://www.youtube.com/watch?v=dQw4w9WgXcQ\">A Simple Link</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = '''\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "\n",
    "<head>\n",
    "  <title>The title of this web page</title>\n",
    "</head>\n",
    "\n",
    "<body>\n",
    "  <h1>My Photos</h1>\n",
    "  <div class='intro'>\n",
    "    <p>These are some photos of my trips.</p>\n",
    "    <img src=\"me.png\">\n",
    "  </div>\n",
    "\n",
    "  <h3>Italy</h3>\n",
    "  <div class='country' id='venice'>\n",
    "    <img src=\"venice1.png\" alt=\"Venice\"> <br />\n",
    "    <img src=\"venice2.png\" alt=\"Venice\"> <br />\n",
    "    <img src=\"rome.png\" alt=\"Roma\">\n",
    "  </div>\n",
    "\n",
    "  <h3>Germany</h3>\n",
    "  <div class='country'>\n",
    "    <img src=\"berlin.png\" alt=\"Berlin\">\n",
    "  </div>\n",
    "  <a href=\"testing\"/>\n",
    "</body>\n",
    "\n",
    "</html>\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using css selectors with BeautifulSoup\n",
    "\n",
    "https://www.crummy.com/software/BeautifulSoup/bs4/doc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods find vs findall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\nThe title of this web page\\n\\n\\nMy Photos\\n\\nThese are some photos of my trips.\\n\\n\\nItaly\\n\\n \\n \\n\\n\\nGermany\\n\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"country\" id=\"venice\">\n",
       "<img alt=\"Venice\" src=\"venice1.png\"/> <br/>\n",
       "<img alt=\"Venice\" src=\"venice2.png\"/> <br/>\n",
       "<img alt=\"Roma\" src=\"rome.png\"/>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('div', attrs={'class':'country'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"country\" id=\"venice\">\n",
       " <img alt=\"Venice\" src=\"venice1.png\"/> <br/>\n",
       " <img alt=\"Venice\" src=\"venice2.png\"/> <br/>\n",
       " <img alt=\"Roma\" src=\"rome.png\"/>\n",
       " </div>, <div class=\"country\">\n",
       " <img alt=\"Berlin\" src=\"berlin.png\"/>\n",
       " </div>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('div', attrs={'class':'country'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"country\" id=\"venice\">\n",
       " <img alt=\"Venice\" src=\"venice1.png\"/> <br/>\n",
       " <img alt=\"Venice\" src=\"venice2.png\"/> <br/>\n",
       " <img alt=\"Roma\" src=\"rome.png\"/>\n",
       " </div>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('div', attrs={'class':'country', 'id':'venice'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods siblings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"intro\">\n",
       " <p>These are some photos of my trips.</p>\n",
       " <img src=\"me.png\"/>\n",
       " </div>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select('div.intro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"intro\">\n",
       " <p>These are some photos of my trips.</p>\n",
       " <img src=\"me.png\"/>\n",
       " </div>, <h3>Italy</h3>, <div class=\"country\" id=\"venice\">\n",
       " <img alt=\"Venice\" src=\"venice1.png\"/> <br/>\n",
       " <img alt=\"Venice\" src=\"venice2.png\"/> <br/>\n",
       " <img alt=\"Roma\" src=\"rome.png\"/>\n",
       " </div>, <h3>Germany</h3>, <div class=\"country\">\n",
       " <img alt=\"Berlin\" src=\"berlin.png\"/>\n",
       " </div>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('h1').find_next_siblings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"intro\">\n",
       " <p>These are some photos of my trips.</p>\n",
       " <img src=\"me.png\"/>\n",
       " </div>, <h1>My Photos</h1>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('h3').find_previous_siblings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .elements attributes\n",
    "\n",
    "The `.next_element` attribute of a string or tag points to whatever was parsed immediately afterwards. It might be the same as `.next_sibling`, but it’s usually drastically different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"intro\">\n",
       "<p>These are some photos of my trips.</p>\n",
       "<img src=\"me.png\"/>\n",
       "</div>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('h1').next_element.next_element.next_element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting css selector information on a webpage\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAABkAAAAWCAYAAAA1vze2AAAB6UlEQVRIDd1U28s5URRd45ZLyCWEcnkRIUVe/RH+XeUZDyQPHrwIIaHw4BJ+rdM3GtOZvtGv73v4dk1zzpl91tp77T1bOR6PT/ywWX4YX8D/ColNlslms8FwOMR0OsX9fpe5vM4sFgtCoRAqlQrS6fTrXLuQksznc2y3W9TrdTyf35dsuVyKoD4iOZ1OsFqtKBaL2oAM17fbDaPRyPC7YU3MZKBFfTwe2u3b2pDkzeubTTAYRDabNfSS1kTmzczW67WQ0eFwwOVywWazgYVnLYzqQayPSFqtFqh/OBxGMplEJBKB2+2G3W4HiVVSfZCmSXiR4N1uF5PJROA4nU5xFo/HkUqlkMlk4Pf79RzmM1EUBYlEQkR9uVwE0Pl8xmKxEDLudjtB8F8kRKVElERrgUAAtVoN1WpVSKf9pq5NdxczYZR8+A+p5vF4EIvFwDebQGbSUwLy0RtBKBmLzFFSKpWES6fTwWw207u/9ops1I/HY/R6PSENZxfbtdlsikuDwQDtdhvlchmFQgEcQf1+H2yCRqMhGuCF/rV4F/jrkNpTkv1+L2YXW1Q1SpPL5ZDP5xGNRuH1esUnBrZaraQk0kxUQNn7er3icDjA5/MJ2ejDWccfVa2P/t7HJHoAM3tp4c1c/MTn75D8A0Qxlq1KHkx8AAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Go on the page you want to scrape  \n",
    "2) Open the inspector tool (right click + inspect or cmd + alt + i)  \n",
    "3) Click on the icon with the mouse: ![image.png](attachment:image.png)\n",
    "4) Select the element in the page you want to scrape. The HTML element will be shown on the right\n",
    "\n",
    "**Note:** You need to repeat that for all the elements you want to scrape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.findAll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='xpath'></a>\n",
    "\n",
    "## Enter XPath and scrapy \n",
    "\n",
    "XPath uses path expressions to select nodes or node-sets in an HTML/XML document. These path expressions look very much like the expressions you see when you work with a traditional computer file system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='xpath'></a>\n",
    "\n",
    "## What is XPath?\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Understanding how to identify elements and attributes within HTML documents gives us the capability to write simple expressions that create structured data.  We can think os XPath like a query language for querying HTML.\n",
    "\n",
    "To make this process easier to deal with, we will be using ChroPath XPath helper, which is a Chrome addon.  It's not necessary, but highly recommended to help build XPath expressions.\n",
    "\n",
    "[chroPath](https://chrome.google.com/webstore/detail/chropath/ljngjbnaijcbncmcnjfhigebomdlkcjo?hl=en)\n",
    "=> to get the Xpath\n",
    "\n",
    "[XPath Helper](https://chrome.google.com/webstore/detail/xpath-helper/hgimnogjllphhhkhlmebbmlgjoejdpjl?hl=en)\n",
    "=> to verify them\n",
    "\n",
    "XPath expressions can select elements, element attributes, and element text.  These selections can be either to a single item, or multiple items.  Generally, if you're not specific enough, you will end up selecting multiple elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting elements matching an _attribute_\n",
    "\n",
    "This will be one of the most common ways you will select items.  HTML DOM elements will be more differentiated based on their \"class\" and \"id\" variables.  Mainly, these types of attributes are used by web developers to refer to specfic elements or a broad set of elements to apply visual characteristics using CSS.\n",
    "\n",
    "```HTML \n",
    "//element[@attribute=\"value\"]\n",
    "```\n",
    "after that each `/` added will move to the next child element.\n",
    "\n",
    "**Generally**\n",
    "\n",
    "- \"class\" attributes within elements usually refer to multiple items\n",
    "- \"id\" attributes are supposed to be unique, but not always\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's go back the above example :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = '''\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "\n",
    "<head>\n",
    "  <title>The title of this web page</title>\n",
    "</head>\n",
    "\n",
    "<body>\n",
    "  <h1>My Photos</h1>\n",
    "  <div class='intro'>\n",
    "    <p>These are some photos of my trips.</p>\n",
    "    <img src=\"me.png\">\n",
    "  </div>\n",
    "\n",
    "  <h3>Italy</h3>\n",
    "  <div class='country' id='venice'>\n",
    "    <img src=\"venice1.png\" alt=\"Venice\"> <br />\n",
    "    <img src=\"venice2.png\" alt=\"Venice\"> <br />\n",
    "    <img src=\"rome.png\" alt=\"Roma\">\n",
    "  </div>\n",
    "\n",
    "  <h3>Germany</h3>\n",
    "  <div class='country'>\n",
    "    <img src=\"berlin.png\" alt=\"Berlin\">\n",
    "  </div>\n",
    "</body>\n",
    "\n",
    "</html>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapy.selector import Selector\n",
    "from scrapy.http import HtmlResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup.find_all('div', attrs={'class':'country'})\n",
    "# becomes with Xpath\n",
    "from pprint import pprint\n",
    "pprint(Selector(text=html).xpath('//div[@class=\"country\"]').extract())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup.find_all('div', attrs={'class':'country', 'id':'venice'})\n",
    "# becomes:\n",
    "pprint(Selector(text=html).xpath('//div[@class=\"country\"][@id=\"venice\"]').extract())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [e for e in soup.find('div', attrs={'class':'intro'}).children][:2]\n",
    "# becomes:\n",
    "pprint(Selector(text=html).xpath('//div[@class=\"intro\"]/p').extract())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Independent Practice:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using either Beautifulsoup (css) or scrapy Selector (Xpath), Create a function that scrape all the articles on techcrunch homepage.\n",
    "https://techcrunch.com/\n",
    "\n",
    "**Bonus:** Implement a recursive loop to load more articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "# get articvles functions \n",
    "def get_articles(num):\n",
    "    driver = webdriver.Chrome(executable_path='./chromedriver/chromedriver')\n",
    "    #got to page\n",
    "    driver.get(\"https://techcrunch.com/\")\n",
    "    \n",
    "    # initial page load source \n",
    "    html = driver.page_source\n",
    "    #conver tpage to soup object\n",
    "    soup = BeautifulSoup(html)\n",
    "    # get number of shwon articles\n",
    "    articles_per_page =  len(soup.find_all('article', {'class' :'post-block post-block--image post-block--unread'}))\n",
    "    #counter\n",
    "    articles_on_page = 0\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # keep adding new articles until desire on page is reached\n",
    "    while articles_on_page <= num:\n",
    "        # scroll to bottom of page\n",
    "        driver.execute_script(\"window.scrollTo(0, 10000);\")\n",
    "        #find more link\n",
    "        next_button = driver.find_element_by_class_name('load-more') \n",
    "        #load more artciles to page\n",
    "        next_button.click()\n",
    "        #add to counter \n",
    "        articles_on_page += articles_per_page\n",
    "        # wait 2 seconds\n",
    "        sleep(5)\n",
    "\n",
    "    \n",
    "    # initial page load source \n",
    "    full_html = driver.page_source\n",
    "    #conver tpage to soup object\n",
    "    soup = BeautifulSoup(full_html)\n",
    "    # create placeholder df\n",
    "    df = pd.DataFrame(columns=['title','author','image'])\n",
    "    # get list of all dom nodes for articles \n",
    "    for article in soup.find_all('article', {'class' :'post-block post-block--image post-block--unread'}):\n",
    "        # get the title\n",
    "        title = article.select_one('a.post-block__title__link').text\n",
    "        # author\n",
    "        author = article.select_one('span.river-byline__authors').select_one('a').text\n",
    "        # image\n",
    "        image = article.select_one('img').attrs['src']\n",
    "        #store each article to df\n",
    "        df.loc[len(df)] = [title, author, image]\n",
    "        \n",
    "    #close selnium\n",
    "    driver.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: unknown error: call function result missing 'value'\n  (Session info: chrome=71.0.3578.80)\n  (Driver info: chromedriver=2.28.455517 (2c6d2707d8ea850c862f04ac066724273981e88f),platform=Mac OS X 10.14.0 x86_64)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-39f3308d591b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0marticles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_articles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0marticles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-97-6f8e3c48fbfb>\u001b[0m in \u001b[0;36mget_articles\u001b[0;34m(num)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0marticles_on_page\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# scroll to bottom of page\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"window.scrollTo(0, 10000);\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;31m#find more link\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mnext_button\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_class_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load-more'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute_script\u001b[0;34m(self, script, *args)\u001b[0m\n\u001b[1;32m    633\u001b[0m         return self.execute(command, {\n\u001b[1;32m    634\u001b[0m             \u001b[0;34m'script'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             'args': converted_args})['value']\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecute_async_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    322\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWebDriverException\u001b[0m: Message: unknown error: call function result missing 'value'\n  (Session info: chrome=71.0.3578.80)\n  (Driver info: chromedriver=2.28.455517 (2c6d2707d8ea850c862f04ac066724273981e88f),platform=Mac OS X 10.14.0 x86_64)\n"
     ]
    }
   ],
   "source": [
    "articles = get_articles(50)\n",
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
